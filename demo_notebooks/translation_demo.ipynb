{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c12c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "from model import Transformer\n",
    "from util import load_config, load_tokenizer, get_tokenizer_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450c352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load config\n",
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = load_tokenizer(**config[\"tokenizer\"])\n",
    "\n",
    "# Create the model\n",
    "transformer = Transformer(\n",
    "    **get_tokenizer_params(tokenizer),\n",
    "    **config[\"transformer_params\"]\n",
    ")\n",
    "\n",
    "# Load the models state_dict\n",
    "model_state_dict = torch.load(\"logs/cloud_run/checkpoint_80000\", map_location=torch.device('cpu'))[\"model_state_dict\"]\n",
    "transformer.load_state_dict(model_state_dict)\n",
    "\n",
    "transformer.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cf707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(sentence):\n",
    "    print(f\"Tokenized sentence: {tokenizer.encode_as_pieces(sentence)}\")\n",
    "    token_tensor = torch.IntTensor(tokenizer.encode(sentence, add_bos=True, add_eos=True))\n",
    "    predictions = transformer.generate(token_tensor)\n",
    "    return tokenizer.decode(predictions.tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec96a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁Germany', '▁is', '▁my', '▁home', '▁country', '.']\n",
      "Deutschland ist mein Heimatland.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Germany is my home country.\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c48045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁We', '▁have', '▁to', '▁discuss', '▁this', '.']\n",
      "Wir müssen das diskutieren.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"We have to discuss this.\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1dc126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁I', '▁love', '▁cake', '.']\n",
      "Ich liebe Kuchen.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love cake.\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543c8278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁Art', 'ificial', '▁intelligence', '▁is', '▁the', '▁superior', '▁field', '▁of', '▁research']\n",
      "Künstliche Intelligenz ist das überlegene Forschungsgebiet\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Artificial intelligence is the superior field of research\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed83843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁Att', 'ention', '▁is', '▁all', '▁you', '▁need', '.']\n",
      "Achtung ist alles, was Sie brauchen.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Attention is all you need.\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8bba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁I', '▁really', '▁liked', '▁pursuing', '▁this', '▁project', '.']\n",
      "Ich habe dieses Projekt wirklich gern verfolgt.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I really liked pursuing this project.\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de221db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁There', \"'\", 's', '▁always', '▁a', '▁bigger', '▁fish']\n",
      "Es gibt immer einen größeren Fisch.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"There's always a bigger fish\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96faaf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁I', '▁am', '▁the', '▁sen', 'ate', '!']\n",
      "Ich bin der Senat!\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I am the senate!\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06eaa296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁I', '▁find', '▁your', '▁lack', '▁of', '▁faith', '▁disturbing']\n",
      "Ich finde Ihren Mangel an Vertrauen verstörend.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I find your lack of faith disturbing\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d37b94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['▁It', \"'\", 's', '▁a', '▁trap', '!', '.']\n",
      "Es ist eine Falle!\n"
     ]
    }
   ],
   "source": [
    "sentence = \"It's a trap!.\"\n",
    "translation = generate_translation(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e137b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
