{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3310792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import load_config, load_tokenizers\n",
    "from model import Transformer\n",
    "import transformer_components\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5f6b4",
   "metadata": {},
   "source": [
    "### Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d16b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "# Load the tokenizers\n",
    "src_tokenizer, tgt_tokenizer = load_tokenizers(**config[\"tokenizer\"])\n",
    "\n",
    "# Create the model\n",
    "transformer = Transformer(\n",
    "    source_vocab_size=src_tokenizer.vocab_size(),\n",
    "    target_vocab_size=tgt_tokenizer.vocab_size(),\n",
    "    bos_idx=tgt_tokenizer.bos_id(),\n",
    "    eos_idx=tgt_tokenizer.eos_id(),\n",
    "    **config[\"transformer_params\"]\n",
    ")\n",
    "\n",
    "stack_size = config[\"transformer_params\"][\"stack_size\"]\n",
    "# Initialize the attention weights queue\n",
    "transformer_components.initialize_attention_weights_queue(3 * stack_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fd8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sequence pair\n",
    "src_sentence = \"hallo welt, aufmerksamkeit ist alles was du brauchst!\"\n",
    "tgt_sentence = \"hello world, attention is all you need!\"\n",
    "\n",
    "src_sequence_ids = src_tokenizer.encode(src_sentence, add_bos=True, add_eos=True)\n",
    "tgt_sequence_ids = tgt_tokenizer.encode(tgt_sentence, add_bos=True, add_eos=True)\n",
    "src_sequence_ids.extend([src_tokenizer.pad_id() for _ in range(4)])\n",
    "tgt_sequence_ids.extend([tgt_tokenizer.pad_id() for _ in range(3)])\n",
    "\n",
    "src_tokens = src_tokenizer.id_to_piece(src_sequence_ids)\n",
    "tgt_tokens = tgt_tokenizer.id_to_piece(tgt_sequence_ids)\n",
    "\n",
    "src_sequence_ids = torch.tensor([src_sequence_ids])\n",
    "tgt_sequence_ids = torch.tensor([tgt_sequence_ids])\n",
    "src_key_padding_mask = src_sequence_ids == src_tokenizer.pad_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca944a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "encoded_src = transformer.encode_source(src_sequence_ids, src_key_padding_mask)\n",
    "\n",
    "# Decode\n",
    "predictions = transformer(encoded_src, tgt_sequence_ids[..., :-1], src_key_padding_mask)\n",
    "\n",
    "attention_weights = list(transformer_components.attention_weights_queue)\n",
    "encoder_attention = attention_weights[:stack_size]\n",
    "decoder_masked_attention = attention_weights[stack_size::2]\n",
    "decoder_encoder_attention = attention_weights[stack_size+1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcc8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_widgets():\n",
    "    stack_idx = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=stack_size - 1,\n",
    "        step=1,\n",
    "        description='Select the stack index:',\n",
    "        style={'description_width': '200px'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    attention_head_idx = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=encoder_attention[0].shape[1] - 1,\n",
    "        step=1,\n",
    "        description='Select the attention head index:',\n",
    "        style={'description_width': '200px'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    return stack_idx, attention_head_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ce82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encoder_attention(stack_idx, attention_head_idx):\n",
    "    attention_weights = encoder_attention[stack_idx][0, attention_head_idx].detach().numpy()\n",
    "\n",
    "    # Plot the weights\n",
    "    plt.imshow(attention_weights, vmin=0, vmax=1)\n",
    "\n",
    "    # Set the xticks and yticks labels\n",
    "    plt.xticks(range(len(src_tokens)), src_tokens, rotation=90, fontsize=8)\n",
    "    plt.yticks(range(len(src_tokens)), src_tokens, fontsize=8)\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_masked_decoder_attention(stack_idx, attention_head_idx):\n",
    "    attention_weights = decoder_masked_attention[stack_idx][0, attention_head_idx].detach().numpy()\n",
    "\n",
    "    # Plot the weights\n",
    "    plt.imshow(attention_weights, vmin=0, vmax=1)\n",
    "\n",
    "    # Set the xticks and yticks labels\n",
    "    plt.xticks(range(len(tgt_tokens)-1), tgt_tokens[:-1], rotation=90, fontsize=8)\n",
    "    plt.yticks(range(len(tgt_tokens)-1), tgt_tokens[:-1], fontsize=8)\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_decoder_encoder_attention(stack_idx, attention_head_idx):\n",
    "    attention_weights = decoder_encoder_attention[stack_idx][0, attention_head_idx].detach().numpy()\n",
    "\n",
    "    # Plot the weights\n",
    "    plt.imshow(attention_weights, vmin=0, vmax=1)\n",
    "\n",
    "    # Set the xticks and yticks labels\n",
    "    plt.xticks(range(len(src_tokens)), src_tokens, rotation=90, fontsize=8)\n",
    "    plt.yticks(range(len(tgt_tokens)-1), tgt_tokens[:-1], fontsize=8)\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85434de2",
   "metadata": {},
   "source": [
    "### Encoder Attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12babb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d96b00c9cd4e83983021033c804f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Select the stack index:', layout=Layout(width='400px'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stack_idx, attention_head_idx = get_widgets()\n",
    "\n",
    "widgets.interact(plot_encoder_attention, stack_idx=stack_idx, attention_head_idx=attention_head_idx)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf00498",
   "metadata": {},
   "source": [
    "### Masked Decoder Attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe2a5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f662e873144245ec819932c47864c797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Select the stack index:', layout=Layout(width='400px'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stack_idx, attention_head_idx = get_widgets()\n",
    "\n",
    "widgets.interact(plot_masked_decoder_attention, stack_idx=stack_idx, attention_head_idx=attention_head_idx)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3229d7a3",
   "metadata": {},
   "source": [
    "### Decoder-Encoder Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb8359a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4dd5fbd30545c29afb58eff4534ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Select the stack index:', layout=Layout(width='400px'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stack_idx, attention_head_idx = get_widgets()\n",
    "\n",
    "widgets.interact(plot_decoder_encoder_attention, stack_idx=stack_idx, attention_head_idx=attention_head_idx)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e70776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
